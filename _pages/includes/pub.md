# üìù Publications 
**( \* = equal contribution)**

- ``TPAMI 2024`` [A survey on non-autoregressive generation for neural machine translation and beyond](https://arxiv.org/pdf/2204.09269.pdf)   
     ***Yisheng Xiao\***, Lijun Wu\*, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, Tie-yan Liu*
    - [Project](https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications) ![](https://img.shields.io/github/stars/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications?style=social&label=Code+Stars) ![](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https://api.semanticscholar.org/graph/v1/paper/67dc33f02c8b5f24cd213b6b5fb5c74cead581aa?fields=citationCount)   
    - The first comprehensive survey on non-aoturegressive generation in research community.
    - We summarize 300+ papers in various fields, including language generation, speech generation, computer vision, etc. 
- ``ICLR 2024`` [Are Bert Family Good Instruction Followers? A Study on Their Potential And Limitations](https://openreview.net/forum?id=x8VNtpCu1I)   
     ***Yisheng Xiao**, Juntao Li, Zechen Sun, Zechang Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Min Zhang*
    - [Project](https://github.com/LitterBrother-Xiao/Instruct_XMLR) ![](https://img.shields.io/github/stars/LitterBrother-Xiao/Instruct_XMLR?style=social&label=Code+Stars)   
    - We are the first to explore the effectiveness of the BERT family for instruction following and zero-shot learning.
    - The final model can outperforms popular LLMs BLOOMZ and mT0 with comparable parameters in several tasks.
- ``AAAI 2023`` [AMOM: Adaptive Masking over Masking for Conditional Masked Language Model](https://ojs.aaai.org/index.php/AAAI/article/view/26615)   
     ***Yisheng Xiao\***, Ruiyang Xu\*, Lijun Wu, Juntao Li, Tao Qin, Tie-Yan Liu, Min Zhang*
    - [Project](https://github.com/amom-nar/AMOM) ![](https://img.shields.io/github/stars/amom-nar/AMOM?style=social&label=Code+Stars)   ![](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https://api.semanticscholar.org/graph/v1/paper/a8767413d9b969b04c9c440a30f6b7c6a9c4b1bc?fields=citationCount)   
- ``EMNLP 2023 Findings`` [Isotropy-Enhanced Conditional Masked Language Models](https://aclanthology.org/2023.findings-emnlp.555.pdf)   
     *Pei Guo\*, **Yisheng Xiao\***, Juntao Li, Yixin Ji, Min Zhang*
    - [Project](https://github.com/AllForward/Isotropy-Enhanced-CMLM) ![](https://img.shields.io/github/stars/AllForward/Isotropy-Enhanced-CMLM?style=social&label=Code+Stars)      ![](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https://api.semanticscholar.org/graph/v1/paper/6f41e863982c72ac6439da65376d97bd1dda5d0b?fields=citationCount)    
- ``AAAI 2023`` [RenewNAT: renewing potential translation for non-autoregressive transformer](https://ojs.aaai.org/index.php/AAAI/article/view/26511)     
     *Pei Guo\*, **Yisheng Xiao\***, Juntao Li, Min Zhang*
    - [Project](https://github.com/AllForward/RenewNAT)  ![](https://img.shields.io/github/stars/AllForward/RenewNAT?style=social&label=Code+Stars)    ![](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https://api.semanticscholar.org/graph/v1/paper/14897d84d004b37b38ddbafc178e518ab31f616e?fields=citationCount)
